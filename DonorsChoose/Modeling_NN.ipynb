{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xd944\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization Runtime: 12.27 Minutes\n",
      "Label Encoder...\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|██████████████                                                                      | 1/6 [00:03<00:15,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|████████████████████████████                                                        | 2/6 [00:03<00:07,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████████                                          | 3/6 [00:04<00:04,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████████████████████████████████                            | 4/6 [00:04<00:02,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|██████████████████████████████████████████████████████████████████████              | 5/6 [00:05<00:01,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:06<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('Data/Ultimate.csv')\n",
    "train = pd.read_csv(\"Data/train.csv\", parse_dates=[\"project_submitted_datetime\"])\n",
    "test = pd.read_csv(\"Data/test.csv\", parse_dates=[\"project_submitted_datetime\"])\n",
    "\n",
    "#df.to_csv('Data/Ultimate.csv',index = False)\n",
    "\n",
    "tfidf_para = {\n",
    "    \"sublinear_tf\":True,\n",
    "    \"strip_accents\":'unicode',\n",
    "    \"stop_words\":\"english\",\n",
    "    \"analyzer\":'word',\n",
    "    \"token_pattern\":r'\\w{1,}',\n",
    "    #\"ngram_range\":(1,1),\n",
    "    \"dtype\":np.float32,\n",
    "    \"norm\":'l2',\n",
    "    \"min_df\":5,\n",
    "    \"max_df\":.9,\n",
    "    \"smooth_idf\":False\n",
    "}\n",
    "\n",
    "# Thanks To\n",
    "# https://www.kaggle.com/lopuhin/eli5-for-mercari\n",
    "# https://www.kaggle.com/jagangupta/understanding-approval-donorschoose-eda-fe-eli5/notebook\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "def get_col(col_name):\n",
    "    return lambda x: x[col_name]\n",
    "\n",
    "df[\"project_title_count\"] = df[\"project_title\"].copy()\n",
    "textcols = [\"text\",\"project_resource_summary\",\"project_title\", \"project_title_count\",\"resource_description\"]\n",
    "vectorizer = FeatureUnion([\n",
    "        ('text',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            max_features=20000,\n",
    "            **tfidf_para,\n",
    "            preprocessor=get_col('text'))),\n",
    "        ('project_resource_summary',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            **tfidf_para,\n",
    "            max_features=2000,\n",
    "            preprocessor=get_col('project_resource_summary'))),\n",
    "        ('project_title',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            **tfidf_para,\n",
    "            max_features=1500,\n",
    "            preprocessor=get_col('project_title'))),\n",
    "        ('project_title_count',CountVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            max_features=1500,\n",
    "            preprocessor=get_col('project_title_count'))),\n",
    "        ('resource_description',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            **tfidf_para,\n",
    "            max_features=2400,\n",
    "            preprocessor=get_col('resource_description'))),\n",
    "#         ('Non_text',DictVectorizer())\n",
    "    ])\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import time\n",
    "for c in textcols:\n",
    "    df[c] = df[c].astype(str)\n",
    "start_vect=time.time()\n",
    "ready_df = vectorizer.fit_transform(df.to_dict('records'))\n",
    "tfvocab = vectorizer.get_feature_names()\n",
    "print(\"Vectorization Runtime: %0.2f Minutes\"%((time.time() - start_vect)/60))\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gc\n",
    "print('Label Encoder...')\n",
    "cols = [\n",
    "    'teacher_id', \n",
    "    'teacher_prefix', \n",
    "    'school_state', \n",
    "    'project_grade_category', \n",
    "    'project_subject_categories', \n",
    "    'project_subject_subcategories'\n",
    "]\n",
    "from tqdm import tqdm\n",
    "for c in tqdm(cols):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df[c].astype(str))\n",
    "    df[c] = le.transform(df[c].astype(str))\n",
    "    print(df[c].isna().any())\n",
    "del le\n",
    "gc.collect()\n",
    "\n",
    "final_test = df[df.project_is_approved.isnull()]\n",
    "traindex = list(set(df.index) - set(final_test.index))\n",
    "testdex = list(set(df.index) - set(traindex))\n",
    "to_drop = ['id','project_essay_1','project_essay_2','project_essay_3','project_essay_4',\n",
    "           'project_resource_summary','project_submitted_datetime','project_title','resource_description',\n",
    "          'text','project_is_approved',\"project_title_count\"]\n",
    "\n",
    "final_test = final_test.drop(columns=to_drop)\n",
    "x = df.loc[traindex,:].drop(columns=to_drop)\n",
    "y = df.loc[traindex,'project_is_approved']\n",
    "\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "x = hstack([csr_matrix(x.values),ready_df[0:182080]])\n",
    "final_test = hstack([csr_matrix(final_test.values),ready_df[182080:]])\n",
    "\n",
    "x = x.tocsr()\n",
    "final_test = final_test.tocsr()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_test = df[df.project_is_approved.isnull()]\n",
    "final_test = final_test.drop(columns=to_drop)\n",
    "x = df.loc[traindex,:].drop(columns=to_drop)\n",
    "y = df.loc[traindex,'project_is_approved']\n",
    "#x = x.fillna(0)\n",
    "#final_test = final_test.fillna(0)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Flatten, concatenate, Dropout, Embedding, SpatialDropout1D\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def breakInput(X1):\n",
    "    X2 = []\n",
    "    i = 0\n",
    "    for n in [n_es1, n_es2, n_prs, n_rd, n_pt, X_cat.shape[1], len(numFeatures)]:\n",
    "        X2.append(X1[:,i:i+n])\n",
    "        i += n\n",
    "    return X2\n",
    "\n",
    "def getModel(HLs, Drop=0.25, OP=optimizers.Adam()):\n",
    "    temp = []\n",
    "    inputs_txt = []\n",
    "    for n in [n_es1, n_es2, n_prs, n_rd, n_pt]:\n",
    "        input_txt = Input((n, ))\n",
    "        X_feat = Dropout(Drop)(input_txt)\n",
    "        X_feat = Dense(int(n/100), activation=\"linear\")(X_feat)\n",
    "        X_feat = Dropout(Drop)(X_feat)\n",
    "        temp.append(X_feat)\n",
    "        inputs_txt.append(input_txt)\n",
    "\n",
    "    x_1 = concatenate(temp)\n",
    "    x_1 = Dense(20, activation=\"relu\")(x_1)\n",
    "    x_1 = Dropout(Drop)(x_1)\n",
    "\n",
    "    input_cat = Input((X_cat.shape[1], ))\n",
    "#     x_2 = Dropout(Drop)(input_cat)\n",
    "    x_2 = Embedding(2, 10, input_length=X_cat.shape[1])(input_cat)\n",
    "    x_2 = SpatialDropout1D(Drop)(x_2)\n",
    "    x_2 = Flatten()(x_2)\n",
    "\n",
    "    input_num = Input((len(numFeatures), ))\n",
    "    x_3 = Dropout(Drop)(input_num)\n",
    "    \n",
    "    x = concatenate([x_1, x_2, x_3])\n",
    "\n",
    "    for HL in HLs:\n",
    "        x = Dense(HL, activation=\"relu\")(x)\n",
    "        x = Dropout(Drop)(x)\n",
    "\n",
    "    output = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs_txt+[input_cat, input_num], outputs=output)\n",
    "    model.compile(\n",
    "            optimizer=OP,\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['binary_accuracy'])\n",
    "    return model\n",
    "\n",
    "def trainNN(X_train, X_val, Tar_train, Tar_val, HL=[50], Drop=0.5, OP=optimizers.Adam()):\n",
    "    file_path='NN.h5'\n",
    "    checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=2, save_best_only=True, save_weights_only=True, mode='min')\n",
    "    early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=6)\n",
    "    lr_reduced = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                   factor=0.5,\n",
    "                                   patience=2,\n",
    "                                   verbose=1,\n",
    "                                   epsilon=3e-4,\n",
    "                                   mode='min')\n",
    "\n",
    "    model = getModel(HL, Drop, OP)\n",
    "    model.fit(breakInput(X_train), Tar_train, validation_data=(breakInput(X_val), Tar_val),\n",
    "                        verbose=2, epochs=50, batch_size=1000, callbacks=[early, lr_reduced, checkpoint])\n",
    "    model.load_weights(file_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "def getCatFeatures(T, Col, Encoder='OneHot'):\n",
    "    ohe = OneHotEncoder()\n",
    "    le = LabelEncoder()\n",
    "    if Encoder=='OneHot':\n",
    "        X = ohe.fit_transform(le.fit_transform(T[Col].fillna('')).reshape((-1,1)))\n",
    "    else:\n",
    "        X = le.fit_transform(T[Col].fillna(''))\n",
    "    return X\n",
    "\n",
    "Encoder = 'OneHot'\n",
    "X_tp = getCatFeatures(df, 'teacher_prefix', Encoder)\n",
    "X_sc = getCatFeatures(df, 'school_state', Encoder)\n",
    "X_pgc = getCatFeatures(df, 'project_grade_category', Encoder)\n",
    "X_psc = getCatFeatures(df, 'project_subject_categories', Encoder)\n",
    "X_pssc = getCatFeatures(df, 'project_subject_subcategories', Encoder)\n",
    "\n",
    "\n",
    "if Encoder=='OneHot':\n",
    "    X_cat = hstack((X_tp, X_sc, X_pgc, X_psc, X_pssc))\n",
    "else:\n",
    "    X_cat = pl.array((X_tp, X_sc, X_pgc, X_psc, X_pssc)).T\n",
    "\n",
    "del X_tp, X_sc, X_pgc, X_psc, X_pssc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<260115x528 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1300575 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numFeatures' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-2fef71e9eb61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn_es1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_es2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_prs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_rd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_pt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHL\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOP\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mYvl3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbreakInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mYts3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbreakInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-ae5f7f073626>\u001b[0m in \u001b[0;36mtrainNN\u001b[1;34m(X_train, X_val, Tar_train, Tar_val, HL, Drop, OP)\u001b[0m\n\u001b[0;32m     64\u001b[0m                                    mode='min')\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDrop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m     model.fit(breakInput(X_train), Tar_train, validation_data=(breakInput(X_val), Tar_val),\n\u001b[0;32m     68\u001b[0m                         verbose=2, epochs=50, batch_size=1000, callbacks=[early, lr_reduced, checkpoint])\n",
      "\u001b[1;32m<ipython-input-20-ae5f7f073626>\u001b[0m in \u001b[0;36mgetModel\u001b[1;34m(HLs, Drop, OP)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mx_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0minput_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumFeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mx_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDrop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'numFeatures' is not defined"
     ]
    }
   ],
   "source": [
    "n_es1, n_es2, n_prs, n_rd, n_pt = 3000, 8000, 2000, 3000, 1000\n",
    "model = trainNN(x_train, x_test, y_train, y_test, HL=[50], Drop=0.5, OP=optimizers.Adam())\n",
    "Yvl3 = model.predict(breakInput(X_val)).squeeze()\n",
    "Yts3 = model.predict(breakInput(Xts)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
