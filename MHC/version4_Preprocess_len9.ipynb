{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "vF55V9imopHw",
    "outputId": "bbb8ba61-0b3c-4862-f48c-af905702b744"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "!cp -R /content/../gdrive/My\\ Drive/MHC/Project/Data/ -d ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AwqJbZnPopH5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import Word2Vec\n",
    "from scipy.sparse import * \n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, Normalizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,HashingVectorizer, TfidfTransformer\n",
    "from sklearn.cluster import KMeans, DBSCAN, AffinityPropagation\n",
    "import math\n",
    "\n",
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "\n",
    "import logging\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aH2ilPYMopH8"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "  df1 = pd.read_csv('./Data/train1.csv', header = None)\n",
    "  df2 = pd.read_csv('./Data/test1.csv', header = None)\n",
    "  df = df1.append(df2)\n",
    "  df.drop_duplicates(inplace = True)\n",
    "  df.reset_index(inplace = True, drop = True)\n",
    "  df.columns = ['peptide', 'aff', 'hla']\n",
    "  df = df.groupby(['peptide','hla']).mean().reset_index()\n",
    "  df = df.groupby('hla').filter(lambda x : len(x)>=30).reset_index(drop = True)\n",
    "  \n",
    "  return df\n",
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D8KHwnkJopH-"
   },
   "outputs": [],
   "source": [
    "def labelenc(df, enc):\n",
    "    enc = LabelEncoder().fit(df.iloc[:,0])\n",
    "    for c in df.columns:\n",
    "        df[c] = enc.transform(df[c])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def tear(serie, n, col):\n",
    "    clus_df = pd.DataFrame(serie.copy())\n",
    "    for i in range(1,n+1):\n",
    "        col_name = col + '_P' + str(i)\n",
    "        clus_df[col_name] = clus_df[col].apply(lambda x : x[i-1])\n",
    "\n",
    "    cols = [c for c in clus_df.columns if c not in [col]]\n",
    "\n",
    "    return clus_df[cols]\n",
    "\n",
    "def hla_preprocess(df):\n",
    "    df['allele_type'] = df['hla'].apply(\n",
    "    lambda x: (x.startswith('DRB') and x[0:3]) or (x.startswith('HLA-DQ') and x[0:6]) or (x.startswith('HLA-DP') and x[0:6]) or x[0:3])\n",
    "\n",
    "    hla_encoder = LabelEncoder()\n",
    "    #hla_encoder.fit(df['hla'])\n",
    "    #np.save('Data/hla_encoder_classes.npy', hla_encoder.classes_)\n",
    "    hla_encoder.classes_ = np.load('./Data/hla_encoder_classes.npy')\n",
    "    df['hla'] = hla_encoder.transform(df['hla'])\n",
    "\n",
    "    allele_type_encoder = LabelEncoder()\n",
    "    #allele_type_encoder.fit(df['allele_type'])\n",
    "    #np.save('Data/allele_type_encoder_classes.npy', allele_type_encoder.classes_)\n",
    "    allele_type_encoder.classes_ = np.load('./Data/allele_type_encoder_classes.npy')\n",
    "    df['allele_type'] = allele_type_encoder.transform(df['allele_type'])\n",
    "\n",
    "    return df\n",
    "df = hla_preprocess(df)\n",
    "df['length'] = df['peptide'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4wTdH-7xPxzp"
   },
   "outputs": [],
   "source": [
    "def multiply(df):\n",
    "    n_iteration = np.int32(df['length'] - 9 +1)\n",
    "    df_result = df.loc[np.repeat(df.index.values,n_iteration)]\n",
    "    df_result.reset_index(inplace = True)\n",
    "    df_result.rename(columns = {'index':'true_index'}, inplace = True)\n",
    "\n",
    "    return df_result\n",
    "df = multiply(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "9c_r3z6OPxzr",
    "outputId": "f6b08d5f-e7a9-4b0c-cd31-0600f3ab847e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String Distinguishing...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c195bddc89aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwindow_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-c195bddc89aa>\u001b[0m in \u001b[0;36mwindow_select\u001b[0;34m(k)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'String Distinguishing...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'core'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'peptide'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'peptide'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LPFR'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'peptide'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'peptide'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RPFR'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'peptide'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n_label'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'length'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'peptide'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m9\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m9\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'length'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done String Distinguishing...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6012\u001b[0m                          \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6013\u001b[0m                          kwds=kwds)\n\u001b[0;32m-> 6014\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6016\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m                                           \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                                           \u001b[0mdummy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                                           labels=labels)\n\u001b[0m\u001b[1;32m    243\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.reduce\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.Reducer.get_result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-c195bddc89aa>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'String Distinguishing...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'core'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'peptide'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'peptide'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LPFR'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'peptide'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'peptide'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RPFR'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'peptide'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n_label'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'length'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'peptide'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m9\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m9\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'length'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done String Distinguishing...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36m_apply_if_callable\u001b[0;34m(maybe_callable, obj, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m     \"\"\"\n\u001b[1;32m    397\u001b[0m     \u001b[0mEvaluate\u001b[0m \u001b[0mpossibly\u001b[0m \u001b[0mcallable\u001b[0m \u001b[0minput\u001b[0m \u001b[0musing\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def L_impute_space(s):\n",
    "    k = 3 - len(s)\n",
    "    return ' '* k + s\n",
    "\n",
    "def R_impute_space(s):\n",
    "    k = 3 - len(s)\n",
    "    return s + ' '* k\n",
    "    \n",
    "def window_select(k):\n",
    "    #tqdm.pandas()\n",
    "    k['true_index'] += 1\n",
    "    k['n_label'] = k[['true_index', 'peptide','hla']].groupby(['peptide','hla']).agg('cumsum')\n",
    "    k['n_label'] /= k['true_index']\n",
    "    k['n_label'] = k['n_label'].map(int) - 1\n",
    "    \n",
    "    print('String Distinguishing...')\n",
    "    k['core'] = k[['peptide', 'n_label']].apply(lambda x : x['peptide'][x['n_label']:x['n_label'] + 9], axis=1)\n",
    "    k['LPFR'] = k[['peptide', 'n_label']].apply(lambda x : x['peptide'][max(x['n_label'] - 3, 0): x['n_label']], axis=1)\n",
    "    k['RPFR'] = k[['peptide', 'n_label','length']].apply(lambda x : x['peptide'][x['n_label'] + 9 : min(x['n_label'] + 9 + 3, x['length'])], axis=1)\n",
    "    print('Done String Distinguishing...')\n",
    "    \n",
    "    print('String Transforming...')\n",
    "    k['len_LPFR'] = k['LPFR'].apply(lambda x: len(x)/3)\n",
    "    k['len_RPFR'] = k['RPFR'].apply(lambda x: len(x)/3)\n",
    "    k['len_peptide_transform'] = k['length'].apply(lambda x : 1/(1+np.exp((x - 15)/2)))\n",
    "    \n",
    "    k['LPFR'] = k['LPFR'].apply(lambda x:L_impute_space(x))\n",
    "    k['RPFR'] = k['RPFR'].apply(lambda x:L_impute_space(x))\n",
    "    return k\n",
    "\n",
    "df = window_select(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gcjZwko8opIB",
    "outputId": "2760e00a-834d-4191-8494-edf96b321dbd"
   },
   "outputs": [],
   "source": [
    "def tfidf(df, col):\n",
    "    vectorizer = TfidfVectorizer(analyzer = 'char')\n",
    "    X = np.array(vectorizer.fit_transform(df[col]).toarray(), dtype=np.float16)\n",
    "    #pickle.dump(vectorizer.fit_transform(df[col]), open(\"tfidf.pickle\", \"wb\"))\n",
    "    for i in range(len(vectorizer.get_feature_names())):\n",
    "        df[col + '_' + vectorizer.get_feature_names()[i] + '_tfidf'] = X[:, i]\n",
    "    \n",
    "    return df\n",
    "\n",
    "for col in tqdm(['core','LPFR', 'RPFR']):\n",
    "    df = pd.concat([df, labelenc(tear(df[col], df[col].map(len).max(), col), LabelEncoder().fit(tear(df[col], df[col].map(len).max(), col).values.flatten()))], axis=1)\n",
    "df = tfidf(df, 'core')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "yVI-2dr6eMXg",
    "outputId": "92ea02bb-0847-4f13-f416-42cc6d942e0b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "op = OptionParser()\n",
    "op.add_option(\"--lsa\",\n",
    "              dest=\"n_components\", type=\"int\",\n",
    "              help=\"Preprocess documents with latent semantic analysis.\")\n",
    "op.add_option(\"--no-minibatch\",\n",
    "              action=\"store_false\", dest=\"minibatch\", default=True,\n",
    "              help=\"Use ordinary k-means algorithm (in batch mode).\")\n",
    "op.add_option(\"--no-idf\",\n",
    "              action=\"store_false\", dest=\"use_idf\", default=True,\n",
    "              help=\"Disable Inverse Document Frequency feature weighting.\")\n",
    "op.add_option(\"--use-hashing\",\n",
    "              action=\"store_true\", default=False,\n",
    "              help=\"Use a hashing feature vectorizer\")\n",
    "op.add_option(\"--n-features\", type=int, default=10000,\n",
    "              help=\"Maximum number of features (dimensions)\"\n",
    "                   \" to extract from text.\")\n",
    "op.add_option(\"--verbose\",\n",
    "              action=\"store_true\", dest=\"verbose\", default=False,\n",
    "              help=\"Print progress reports inside k-means algorithm.\")\n",
    "\n",
    "print(__doc__)\n",
    "op.print_help()\n",
    "\n",
    "def is_interactive():\n",
    "    return not hasattr(sys.modules['__main__'], '__file__')\n",
    "  \n",
    "argv = [] if is_interactive() else sys.argv[1:]\n",
    "(opts, args) = op.parse_args(argv)\n",
    "if len(args) > 0:\n",
    "    op.error(\"this script takes no arguments.\")\n",
    "    sys.exit(1)\n",
    "    \n",
    "    \n",
    "k = df['core'].apply(lambda x: \" \".join(x))\n",
    "dataset = k\n",
    "\n",
    "\n",
    "#labels = dataset.target\n",
    "true_k = int(math.sqrt(k.nunique()))\n",
    "\n",
    "print(\"Extracting features from the training dataset \"\n",
    "      \"using a sparse vectorizer\")\n",
    "t0 = time()\n",
    "if opts.use_hashing:\n",
    "    if opts.use_idf:\n",
    "        # Perform an IDF normalization on the output of HashingVectorizer\n",
    "        hasher = HashingVectorizer(n_features=opts.n_features,analyzer = 'char',\n",
    "                                   stop_words='english', alternate_sign=False,\n",
    "                                   norm=None, binary=False)\n",
    "        vectorizer = make_pipeline(hasher, TfidfTransformer())\n",
    "    else:\n",
    "        vectorizer = HashingVectorizer(n_features=opts.n_features,\n",
    "                                       stop_words='english',analyzer = 'char',\n",
    "                                       alternate_sign=False, norm='l2',\n",
    "                                       binary=False)\n",
    "else:\n",
    "    vectorizer = TfidfVectorizer(max_df=0.5, max_features=opts.n_features,\n",
    "                                 min_df=2, stop_words='english',analyzer = 'char',\n",
    "                                 use_idf=opts.use_idf)\n",
    "X = vectorizer.fit_transform(dataset)\n",
    "\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "print(\"n_samples: %d, n_features: %d\" % X.shape)\n",
    "print()\n",
    "\n",
    "if opts.n_components:\n",
    "    print(\"Performing dimensionality reduction using LSA\")\n",
    "    t0 = time()\n",
    "    # Vectorizer results are normalized, which makes KMeans behave as\n",
    "    # spherical k-means for better results. Since LSA/SVD results are\n",
    "    # not normalized, we have to redo the normalization.\n",
    "    svd = TruncatedSVD(opts.n_components)\n",
    "    normalizer = Normalizer(copy=False)\n",
    "    lsa = make_pipeline(svd, normalizer)\n",
    "\n",
    "    X = lsa.fit_transform(X)\n",
    "\n",
    "    print(\"done in %fs\" % (time() - t0))\n",
    "\n",
    "    explained_variance = svd.explained_variance_ratio_.sum()\n",
    "    print(\"Explained variance of the SVD step: {}%\".format(\n",
    "        int(explained_variance * 100)))\n",
    "\n",
    "    print()\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Do the actual clustering\n",
    "\n",
    "if opts.minibatch:\n",
    "    km = MiniBatchKMeans(n_clusters=true_k, init='k-means++', n_init=1,\n",
    "                         init_size=1000, batch_size=1000, verbose=opts.verbose,\n",
    "                        random_state = 42)\n",
    "else:\n",
    "    km = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1,\n",
    "                verbose=opts.verbose, random_state = 42)\n",
    "\n",
    "print(\"Clustering sparse data with %s\" % km)\n",
    "t0 = time()\n",
    "km.fit(X)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "\n",
    "'''if not opts.use_hashing:\n",
    "    print(\"Top terms per cluster:\")\n",
    "\n",
    "    if opts.n_components:\n",
    "        original_space_centroids = svd.inverse_transform(km.cluster_centers_)\n",
    "        order_centroids = original_space_centroids.argsort()[:, ::-1]\n",
    "    else:\n",
    "        order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    for i in range(true_k):\n",
    "        print(\"Cluster %d:\" % i, end='')\n",
    "        for ind in order_centroids[i, :10]:\n",
    "            print(' %s' % terms[ind], end='')\n",
    "        print()'''\n",
    "        \n",
    "df['cluster'] = km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CE9z3ra5u0ZS",
    "outputId": "70f672bf-778e-4fdc-ecf4-2fdcd8cc9a97"
   },
   "outputs": [],
   "source": [
    "def mean_encoding(df):\n",
    "    groupby_list = ['hla', 'allele_type', 'core_P1', 'core_P2', 'core_P3', 'core_P4',\n",
    "                    'core_P5', 'core_P6', 'core_P7', 'core_P8', 'core_P9', 'LPFR_P1',\n",
    "                    'LPFR_P2', 'LPFR_P3', 'RPFR_P1', 'RPFR_P2', 'RPFR_P3', 'cluster',]\n",
    "\n",
    "    for cat in tqdm(groupby_list):\n",
    "        tmp = df.groupby(cat).agg({'aff':['mean', 'std']})\n",
    "\n",
    "        tmp.columns = [cat + '_' + s for s in ['mean', 'std']]\n",
    "        tmp[cat] = tmp.index\n",
    "        df = pd.merge(df, tmp, on = cat, how = 'left')\n",
    "        \n",
    "    return df\n",
    "  \n",
    "df = mean_encoding(df)\n",
    "df['peptide_nunique'] = df['peptide'].apply(lambda x: len(''.join(set(x))))\n",
    "df['unique_rate'] = df['peptide_nunique']/ df['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aAMYWFcuYe0i",
    "outputId": "e6536a6a-5c52-4cfd-c8a8-88c673f20493"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 975202/975202 [00:20<00:00, 47434.95it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('Data/blosum62.json') as json_data:\n",
    "    d = json.load(json_data)\n",
    "output = {\n",
    "    'p1':[],\n",
    "    'p2':[],\n",
    "    'p3':[],\n",
    "    'p4':[],\n",
    "    'p5':[],\n",
    "    'p6':[],\n",
    "    'p7':[],\n",
    "    'p8':[],\n",
    "    'p9':[],\n",
    "}\n",
    "\n",
    "for string in tqdm(df['core']):\n",
    "    cnt = 1\n",
    "    for s in string:\n",
    "        tmp = 0\n",
    "        for k in string:\n",
    "            tmp += d[s][k]\n",
    "        loc = 'p'+str(cnt)\n",
    "        cnt += 1\n",
    "        output[loc].append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df = pd.concat([df,pd.DataFrame(output)], axis = 1)\n",
    "df['blosum_sum'] = df['p1'] + df['p2'] + df['p3'] + df['p4'] + df['p5'] + df['p6'] + df['p7'] + df['p8'] + df['p9']\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "countvec...done\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "feature_engineered = {\n",
    "  'hla':['hla', 'allele_type'],\n",
    "  'length':['length'],\n",
    "  'len_PFR':['len_LPFR', 'len_RPFR', 'len_peptide_transform'],\n",
    "  'core':['core_P1', 'core_P2', 'core_P3', 'core_P4', 'core_P5', 'core_P6', 'core_P7', 'core_P8', 'core_P9'],\n",
    "  'PFR':['LPFR_P1', 'LPFR_P2', 'LPFR_P3', 'RPFR_P1', 'RPFR_P2', 'RPFR_P3'],\n",
    "  'core_tfidf':[],\n",
    "  'core_count':[],\n",
    "  'cluster':['cluster'],\n",
    "  'unique':['peptide_nunique','unique_rate'],\n",
    "  'blosum_sum':['blosum_sum']\n",
    "\n",
    "}\n",
    "def countvec(df, col, json):\n",
    "  with open(\"./Data/count_vectorizer.pickle\", \"rb\") as input_file:\n",
    "    vectorizer = pickle.load(input_file)\n",
    "  X = np.array(vectorizer.fit_transform(list(df['core'])).toarray(), dtype=np.float16)\n",
    "\n",
    "  for i in range(len(vectorizer.get_feature_names())):\n",
    "    name = str(col) + '_' + str(vectorizer.get_feature_names()[i]) + '_count'\n",
    "    df[name] = X[:, i]\n",
    "    json['core_count'].append(name)\n",
    "  print('countvec...done')\n",
    "  return df, json\n",
    "\n",
    "df, ace = countvec(df, 'core', feature_engineered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hla': ['hla', 'allele_type'],\n",
       " 'length': ['length'],\n",
       " 'len_PFR': ['len_LPFR', 'len_RPFR', 'len_peptide_transform'],\n",
       " 'core': ['core_P1',\n",
       "  'core_P2',\n",
       "  'core_P3',\n",
       "  'core_P4',\n",
       "  'core_P5',\n",
       "  'core_P6',\n",
       "  'core_P7',\n",
       "  'core_P8',\n",
       "  'core_P9'],\n",
       " 'PFR': ['LPFR_P1', 'LPFR_P2', 'LPFR_P3', 'RPFR_P1', 'RPFR_P2', 'RPFR_P3'],\n",
       " 'core_tfidf': [],\n",
       " 'core_count': ['core_a_count',\n",
       "  'core_c_count',\n",
       "  'core_d_count',\n",
       "  'core_e_count',\n",
       "  'core_f_count',\n",
       "  'core_g_count',\n",
       "  'core_h_count',\n",
       "  'core_i_count',\n",
       "  'core_k_count',\n",
       "  'core_l_count',\n",
       "  'core_m_count',\n",
       "  'core_n_count',\n",
       "  'core_p_count',\n",
       "  'core_q_count',\n",
       "  'core_r_count',\n",
       "  'core_s_count',\n",
       "  'core_t_count',\n",
       "  'core_v_count',\n",
       "  'core_w_count',\n",
       "  'core_y_count'],\n",
       " 'cluster': ['cluster'],\n",
       " 'unique': ['peptide_nunique', 'unique_rate'],\n",
       " 'blosum_sum': ['blosum_sum']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_engineered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "cols_to_drop = ['aff','peptide','core','LPFR','RPFR','true_index','n_label']\n",
    "\n",
    "X = df.drop(columns= cols_to_drop, axis = 1)\n",
    "y = df['aff'].apply(lambda x: 1 if x >= 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True,  True,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False,  True, False, False, False,\n",
       "        True, False,  True, False,  True,  True, False,  True, False,\n",
       "       False,  True,  True,  True, False, False, False, False,  True])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "estimator = RandomForestClassifier()\n",
    "selector = RFECV(estimator, step=1, cv=5, verbose = 1, n_jobs = -1)\n",
    "selector = selector.fit(X, y)\n",
    "selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hla', 'core_a_tfidf', 'core_l_tfidf', 'cluster', 'hla_mean', 'hla_std',\n",
       "       'LPFR_P2_mean', 'LPFR_P3_mean', 'RPFR_P2_mean', 'RPFR_P3_mean',\n",
       "       'cluster_mean', 'cluster_std', 'unique_rate', 'p3', 'p4', 'p5',\n",
       "       'blosum_sum'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns[selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "estimator = SVC()\n",
    "svc_selector = RFECV(estimator, step=1, cv=5, verbose = 1, n_jobs = -1).fit(X, y)\n",
    "X.columns[svc_selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svc_selector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-90527b8e8896>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msvc_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'svc_selector' is not defined"
     ]
    }
   ],
   "source": [
    "X.columns[svc_selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LPFR_P3', 'p3', 'p4'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(X.columns) - set(['hla', 'allele_type', 'length', 'len_LPFR', 'len_RPFR',\n",
    "       'len_peptide_transform', 'core_P1', 'core_P2', 'core_P3', 'core_P4',\n",
    "       'core_P5', 'core_P6', 'core_P7', 'core_P8', 'core_P9', 'LPFR_P1',\n",
    "       'LPFR_P2', 'RPFR_P1', 'RPFR_P2', 'RPFR_P3', 'core_a_tfidf',\n",
    "       'core_c_tfidf', 'core_d_tfidf', 'core_e_tfidf', 'core_f_tfidf',\n",
    "       'core_g_tfidf', 'core_h_tfidf', 'core_i_tfidf', 'core_k_tfidf',\n",
    "       'core_l_tfidf', 'core_m_tfidf', 'core_n_tfidf', 'core_p_tfidf',\n",
    "       'core_q_tfidf', 'core_r_tfidf', 'core_s_tfidf', 'core_t_tfidf',\n",
    "       'core_v_tfidf', 'core_w_tfidf', 'core_y_tfidf', 'cluster', 'hla_mean',\n",
    "       'hla_std', 'allele_type_mean', 'allele_type_std', 'core_P1_mean',\n",
    "       'core_P1_std', 'core_P2_mean', 'core_P2_std', 'core_P3_mean',\n",
    "       'core_P3_std', 'core_P4_mean', 'core_P4_std', 'core_P5_mean',\n",
    "       'core_P5_std', 'core_P6_mean', 'core_P6_std', 'core_P7_mean',\n",
    "       'core_P7_std', 'core_P8_mean', 'core_P8_std', 'core_P9_mean',\n",
    "       'core_P9_std', 'LPFR_P1_mean', 'LPFR_P1_std', 'LPFR_P2_mean',\n",
    "       'LPFR_P2_std', 'LPFR_P3_mean', 'LPFR_P3_std', 'RPFR_P1_mean',\n",
    "       'RPFR_P1_std', 'RPFR_P2_mean', 'RPFR_P2_std', 'RPFR_P3_mean',\n",
    "       'RPFR_P3_std', 'cluster_mean', 'cluster_std', 'peptide_nunique',\n",
    "       'unique_rate', 'p1', 'p2', 'p5', 'p6', 'p7', 'p8', 'p9', 'blosum_sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['hla', 'allele_type', 'length', 'len_LPFR', 'len_RPFR',\n",
       "       'len_peptide_transform', 'core_P1', 'core_P2', 'core_P3', 'core_P4',\n",
       "       'core_P5', 'core_P6', 'core_P7', 'core_P8', 'core_P9', 'LPFR_P1',\n",
       "       'LPFR_P2', 'RPFR_P1', 'RPFR_P2', 'RPFR_P3', 'core_a_tfidf',\n",
       "       'core_c_tfidf', 'core_d_tfidf', 'core_e_tfidf', 'core_f_tfidf',\n",
       "       'core_g_tfidf', 'core_h_tfidf', 'core_i_tfidf', 'core_k_tfidf',\n",
       "       'core_l_tfidf', 'core_m_tfidf', 'core_n_tfidf', 'core_p_tfidf',\n",
       "       'core_q_tfidf', 'core_r_tfidf', 'core_s_tfidf', 'core_t_tfidf',\n",
       "       'core_v_tfidf', 'core_w_tfidf', 'core_y_tfidf', 'cluster', 'hla_mean',\n",
       "       'hla_std', 'allele_type_mean', 'allele_type_std', 'core_P1_mean',\n",
       "       'core_P1_std', 'core_P2_mean', 'core_P2_std', 'core_P3_mean',\n",
       "       'core_P3_std', 'core_P4_mean', 'core_P4_std', 'core_P5_mean',\n",
       "       'core_P5_std', 'core_P6_mean', 'core_P6_std', 'core_P7_mean',\n",
       "       'core_P7_std', 'core_P8_mean', 'core_P8_std', 'core_P9_mean',\n",
       "       'core_P9_std', 'LPFR_P1_mean', 'LPFR_P1_std', 'LPFR_P2_mean',\n",
       "       'LPFR_P2_std', 'LPFR_P3_mean', 'LPFR_P3_std', 'RPFR_P1_mean',\n",
       "       'RPFR_P1_std', 'RPFR_P2_mean', 'RPFR_P2_std', 'RPFR_P3_mean',\n",
       "       'RPFR_P3_std', 'cluster_mean', 'cluster_std', 'peptide_nunique',\n",
       "       'unique_rate', 'p1', 'p2', 'p5', 'p6', 'p7', 'p8', 'p9', 'blosum_sum'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "estimator = RidgeClassifier()\n",
    "RidgeClassifier_selector = RFECV(estimator, step=1, cv=5, verbose = 1, n_jobs = -1).fit(X, y)\n",
    "X.columns[RidgeClassifier_selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['len_peptide_transform', 'core_a_tfidf', 'core_c_tfidf', 'core_e_tfidf',\n",
       "       'core_i_tfidf', 'core_k_tfidf', 'core_l_tfidf', 'core_n_tfidf',\n",
       "       'hla_mean', 'hla_std', 'allele_type_mean', 'allele_type_std',\n",
       "       'core_P1_mean', 'core_P1_std', 'core_P2_std', 'core_P3_mean',\n",
       "       'core_P4_mean', 'core_P4_std', 'core_P5_mean', 'core_P5_std',\n",
       "       'core_P6_mean', 'core_P6_std', 'core_P7_mean', 'core_P7_std',\n",
       "       'core_P8_mean', 'core_P8_std', 'core_P9_mean', 'core_P9_std',\n",
       "       'LPFR_P1_mean', 'LPFR_P1_std', 'LPFR_P2_mean', 'LPFR_P3_mean',\n",
       "       'LPFR_P3_std', 'RPFR_P1_mean', 'RPFR_P1_std', 'RPFR_P2_mean',\n",
       "       'RPFR_P2_std', 'RPFR_P3_mean', 'RPFR_P3_std', 'cluster_mean',\n",
       "       'unique_rate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "estimator = SGDClassifier()\n",
    "SGDClassifier_selector = RFECV(estimator, step=1, cv=5, verbose = 1, n_jobs = -1).fit(X, y)\n",
    "X.columns[SGDClassifier_selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The classifier does not expose \"coef_\" or \"feature_importances_\" attributes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.7/site-packages/sklearn/feature_selection/rfe.py\", line 32, in _rfe_single_fit\n    X_train, y_train, lambda estimator, features:\n  File \"/usr/local/lib/python3.7/site-packages/sklearn/feature_selection/rfe.py\", line 187, in _fit\n    raise RuntimeError('The classifier does not expose '\nRuntimeError: The classifier does not expose \"coef_\" or \"feature_importances_\" attributes\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-6acaa7240d07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneural_network\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mMLPClassifier_selector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFECV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMLPClassifier_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/feature_selection/rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    512\u001b[0m         scores = parallel(\n\u001b[1;32m    513\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m             for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The classifier does not expose \"coef_\" or \"feature_importances_\" attributes"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "estimator = MLPClassifier()\n",
    "MLPClassifier_selector = RFECV(estimator, step=1, cv=5, verbose = 1, n_jobs = -1).fit(X, y)\n",
    "X.columns[MLPClassifier_selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['aff','peptide','core','LPFR','RPFR','true_index','n_label']\n",
    "\n",
    "X = df.drop(columns= cols_to_drop, axis = 1)\n",
    "y = df['aff'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'num_leaves': int(params['num_leaves']),\n",
    "        'colsample_bytree': '{:.3f}'.format(params['colsample_bytree']),\n",
    "        'min_data_in_leaf': int(params['min_data_in_leaf']),\n",
    "        'bagging_fraction': params['bagging_fraction'],\n",
    "        'bagging_freq': int(params['bagging_freq']),\n",
    "        'feature_fraction': params['feature_fraction'],\n",
    "        'max_bin': int(params['max_bin']),\n",
    "        'boosting': str(params['boosting']),\n",
    "        'min_data_in_leaf': int(params['min_data_in_leaf']),\n",
    "        'min_sum_hessian_in_leaf': params['min_sum_hessian_in_leaf'],\n",
    "        'min_gain_to_split': params['min_gain_to_split'],\n",
    "        'lambda_l2': params['lambda_l2'],\n",
    "        'lambda_l1': params['lambda_l1'],\n",
    "        'scale_pos_weight': params['scale_pos_weight'],\n",
    "        'learning_rate': 0.01,\n",
    "        'num_iterations':200,\n",
    "        'seed':0,\n",
    "        \n",
    "    }\n",
    "    \n",
    "    clf = lgb.LGBMClassifier(\n",
    "        #num_boost_round = 500,\n",
    "        #learning_rate = 0.01,\n",
    "        **params\n",
    "    )\n",
    "    \n",
    "    score = cross_val_score(clf, X, y, scoring='roc_auc', cv=KFold(n_splits = 5)).mean()\n",
    "    #print(\"AUC {:.3f} params {}\".format(score, params))\n",
    "    return -score\n",
    "\n",
    "space = {\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0),\n",
    "    'max_depth': hp.randint('max_depth', 9) + 1,\n",
    "    'min_data_in_leaf': hp.quniform('min_data_in_leaf',100, 1000, 2),\n",
    "    'num_leaves': int(hp.quniform('num_leaves', 8, 128, 2)),\n",
    "    'bagging_fraction': hp.uniform('bagging_fraction', 0.7, 0.95),\n",
    "    'bagging_freq': hp.randint('bagging_freq', 9) + 1,\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.7, 0.95),\n",
    "    'max_bin': hp.randint('max_bin', 255) + 100,\n",
    "    'boosting': hp.choice('boosting', [\"dart\", \"gbdt\"]),\n",
    "    'min_data_in_leaf': hp.randint('min_data_in_leaf', 20) + 10,\n",
    "    'min_sum_hessian_in_leaf': hp.loguniform('min_sum_hessian_in_leaf', 1e-4, 1e-2),\n",
    "    'min_gain_to_split': hp.uniform('min_gain_to_split', 5, 50),\n",
    "    'lambda_l2': hp.uniform('lambda_l2', 0, 1),\n",
    "    'lambda_l1': hp.uniform('lambda_l1', 0, 1),\n",
    "    'scale_pos_weight': hp.uniform('scale_pos_weight', 0.1, 1),\n",
    "    \n",
    "}\n",
    "\n",
    "best_params = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=1000\n",
    ")\n",
    "\n",
    "import json\n",
    "with open('best_param.json', 'w') as outfile:\n",
    "    json.dump(best_params, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's auc: 0.816523\tvalid_1's auc: 0.785778\n",
      "[1000]\ttraining's auc: 0.842899\tvalid_1's auc: 0.809729\n",
      "[1500]\ttraining's auc: 0.857626\tvalid_1's auc: 0.819999\n",
      "[2000]\ttraining's auc: 0.868209\tvalid_1's auc: 0.825767\n",
      "[2500]\ttraining's auc: 0.877032\tvalid_1's auc: 0.83013\n",
      "[3000]\ttraining's auc: 0.883801\tvalid_1's auc: 0.833065\n",
      "[3500]\ttraining's auc: 0.889998\tvalid_1's auc: 0.835088\n",
      "[4000]\ttraining's auc: 0.895786\tvalid_1's auc: 0.836218\n",
      "[4500]\ttraining's auc: 0.901078\tvalid_1's auc: 0.837176\n",
      "[5000]\ttraining's auc: 0.905948\tvalid_1's auc: 0.838086\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-4210753f748c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_valid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         )\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalid_sets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                 \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36meval_train\u001b[0;34m(self, feval)\u001b[0m\n\u001b[1;32m   1914\u001b[0m             \u001b[0mList\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \"\"\"\n\u001b[0;32m-> 1916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__inner_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__train_data_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[0;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[1;32m   2320\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2321\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_out_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2322\u001b[0;31m                 result.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[1;32m   2323\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtmp_out_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_inner_eval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wrong length of eval results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cols_to_drop = ['aff','peptide','core','LPFR','RPFR','true_index','n_label']\n",
    "\n",
    "#df.rename(columns={'aff_x':'aff'},  inplace = True)\n",
    "X = df.drop(columns= cols_to_drop, axis = 1)\n",
    "#X = df[['hla_mean', 'hla', 'cluster_mean', 'length', 'unique_rate', 'cluster_std']]\n",
    "y = df['aff'].apply(lambda x: 1 if x >= (1-log (500)/log(50000)) else 0)\n",
    "\n",
    "auc_score = []\n",
    "FI = []\n",
    "N_FOLDS = 5\n",
    "\n",
    "oof_preds = np.zeros(X.shape[0])\n",
    "#sub_preds = np.zeros(test_df.shape[0])\n",
    "feature_importance_df = pd.DataFrame()\n",
    "feats = [f for f in X.columns]\n",
    "\n",
    "for i in range(N_FOLDS):\n",
    "    max_index = df.true_index.max()\n",
    "    k = math.floor(max_index/N_FOLDS)\n",
    "    if i == N_FOLDS-1:\n",
    "        train_index, test_index = list(set(df.index) - set(df[df['true_index'].between(k*i+1, max_index, inclusive=True)].index)), list(set(df[df['true_index'].between(k*i+1, max_index, inclusive=True)].index))\n",
    "    else: \n",
    "        train_index, test_index = list(set(df.index) - set(df[df['true_index'].between(k*i+1, k*(i+1), inclusive=True)].index)), list(set(df[df['true_index'].between(k*i+1, k*(i+1), inclusive=True)].index))\n",
    "    \n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "    \n",
    "    # Parameters\n",
    "    MAX_BOOST_ROUNDS = 100000\n",
    "    LEARNING_RATE = 0.01\n",
    "\n",
    "    #x_train = x_train.values.astype(np.float32, copy=False)\n",
    "    d_train = lgb.Dataset(X_train, label= y_train)\n",
    "    d_valid = lgb.Dataset(X_test, label = y_test)\n",
    "    # Params\n",
    "    params = {\n",
    "        'objective':'binary',\n",
    "        'metric': 'auc',\n",
    "        \"boosting\": 'gbdt', \n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'seed': 0,\n",
    "        #'is_unbalance': True,\n",
    "    }\n",
    "    #Model\n",
    "    clf = lgb.train(\n",
    "            params=params,\n",
    "            train_set=d_train,\n",
    "            num_boost_round = MAX_BOOST_ROUNDS,\n",
    "            valid_sets=[d_train, d_valid],\n",
    "            early_stopping_rounds=200,\n",
    "            verbose_eval=500\n",
    "        )\n",
    "    \n",
    "    oof_preds[test_index] = clf.predict(X_test)\n",
    "'''    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = feats\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance(importance_type='gain')\n",
    "    fold_importance_df[\"fold\"] = N_FOLDS + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "feature_importance_df.to_csv('feature_importance_df_no_core.csv', index = False)'''\n",
    "#!cp ./feature_importance_df2.csv -d /content/../gdrive/My\\ Drive/MHC/Project/Data/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "colab_type": "code",
    "id": "oqYU3aEewcxO",
    "outputId": "9255be95-9040-4f8d-ed0d-b5ecc19c8aa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's auc: 0.50888\tvalid_1's auc: 0.501062\n",
      "Training until validation scores don't improve for 200 rounds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-f907b530ec34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_valid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         )\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalid_sets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                 \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36meval_train\u001b[0;34m(self, feval)\u001b[0m\n\u001b[1;32m   1914\u001b[0m             \u001b[0mList\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \"\"\"\n\u001b[0;32m-> 1916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__inner_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__train_data_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[0;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[1;32m   2320\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2321\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_out_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2322\u001b[0;31m                 result.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[1;32m   2323\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtmp_out_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_inner_eval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wrong length of eval results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cols_to_drop = ['aff','peptide','core','LPFR','RPFR','true_index','n_label']\n",
    "\n",
    "X = df.drop(columns= cols_to_drop, axis = 1).sample(frac=1).reset_index(drop = True)\n",
    "#X = df[['hla_mean', 'hla', 'cluster_mean', 'length', 'unique_rate', 'cluster_std']]\n",
    "y = df['aff'].apply(lambda x: 1 if x >= (1-log (500)/log(50000)) else 0)\n",
    "\n",
    "auc_score = []\n",
    "FI = []\n",
    "N_FOLDS = 5\n",
    "\n",
    "oof_preds = np.zeros(X.shape[0])\n",
    "#sub_preds = np.zeros(test_df.shape[0])\n",
    "feature_importance_df = pd.DataFrame()\n",
    "feats = [f for f in X.columns]\n",
    "\n",
    "for train_index, test_index in KFold(n_splits=N_FOLDS).split(X):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "    \n",
    "    # Parameters\n",
    "    MAX_BOOST_ROUNDS = 100000\n",
    "    LEARNING_RATE = 0.01\n",
    "\n",
    "    #x_train = x_train.values.astype(np.float32, copy=False)\n",
    "    d_train = lgb.Dataset(X_train, label= y_train)\n",
    "    d_valid = lgb.Dataset(X_test, label = y_test)\n",
    "    # Params\n",
    "    params = {\n",
    "        'objective':'binary',\n",
    "        'metric': 'auc',\n",
    "        \"boosting\": 'gbdt', \n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'seed': 0,\n",
    "        #'is_unbalance': True,\n",
    "    }\n",
    "    #Model\n",
    "    clf = lgb.train(\n",
    "            params=params,\n",
    "            train_set=d_train,\n",
    "            num_boost_round = MAX_BOOST_ROUNDS,\n",
    "            valid_sets=[d_train, d_valid],\n",
    "            early_stopping_rounds=200,\n",
    "            verbose_eval=500\n",
    "        )\n",
    "    \n",
    "    oof_preds[test_index] = clf.predict(X_test)\n",
    "'''    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = feats\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance(importance_type='gain')\n",
    "    fold_importance_df[\"fold\"] = N_FOLDS + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "feature_importance_df.to_csv('feature_importance_df_no_core.csv', index = False)'''\n",
    "#!cp ./feature_importance_df2.csv -d /content/../gdrive/My\\ Drive/MHC/Project/Data/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2181161 , 0.22773271, 0.24020651, ..., 0.88992833, 0.89454248,\n",
       "       0.87875922])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.save_model('mode.txt')\n",
    "bst = lgb.Booster(model_file='mode.txt')\n",
    "bst.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8480222721742423"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(k['aff'].apply(lambda x: 1 if x >= (1-log (500)/log(50000)) else 0), k['oof_preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gbdt all feature + vector -p_number\n",
    "df['oof_preds'] = oof_preds\n",
    "idx = df.groupby(['true_index'])['oof_preds'].transform(max) == df['oof_preds']\n",
    "k = df[idx]\n",
    "df.drop(columns = 'oof_preds', inplace = True)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(k['aff'].apply(lambda x: 1 if x >= (1-log (500)/log(50000)) else 0), k['oof_preds'])\n",
    "k.drop(columns = ['aff', 'true_index','n_label']).to_csv('stage2_input2.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133348, 98)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.846699634196055"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#goss\n",
    "'''cols_to_drop = ['aff','peptide','core','LPFR','RPFR','true_index','n_label', 'core_P1', 'core_P2', 'core_P3', 'core_P4',\n",
    "                    'core_P5', 'core_P6', 'core_P7', 'core_P8', 'core_P9','allele_type', 'len_peptide_transform',\n",
    "                'core_P1_mean', 'core_P1_std', 'core_P2_std', 'core_P3_mean',\n",
    "                 'core_P4_mean', 'core_P4_std', 'core_P5_mean', 'core_P5_std',\n",
    "                 'core_P6_mean', 'core_P6_std', 'core_P7_mean', 'core_P7_std',\n",
    "                 'core_P8_mean', 'core_P8_std', 'core_P9_mean', 'core_P9_std',]'''\n",
    "df['oof_preds'] = oof_preds\n",
    "idx = df.groupby(['true_index'])['oof_preds'].transform(max) == df['oof_preds']\n",
    "k = df[idx]\n",
    "df.drop(columns = 'oof_preds', inplace = True)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(k['aff'].apply(lambda x: 1 if x >= (1-log (500)/log(50000)) else 0), k['oof_preds'])\n",
    "#df.drop(columns='oof_preds',axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8489972041409461"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#goss\n",
    "# cols_to_drop = ['aff','peptide','core','LPFR','RPFR','true_index','n_label', 'core_P1', 'core_P2', 'core_P3', 'core_P4','core_P5', 'core_P6', 'core_P7', 'core_P8', 'core_P9']\n",
    "df['oof_preds'] = oof_preds\n",
    "idx = df.groupby(['true_index'])['oof_preds'].transform(max) == df['oof_preds']\n",
    "k = df[idx]\n",
    "df.drop(columns = 'oof_preds', inplace = True)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(k['aff'].apply(lambda x: 1 if x >= (1-log (500)/log(50000)) else 0), k['oof_preds'])\n",
    "#df.drop(columns='oof_preds',axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8537717807422511"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gbdt\n",
    "df['oof_preds'] = oof_preds\n",
    "idx = df.groupby(['true_index'])['oof_preds'].transform(max) == df['oof_preds']\n",
    "k = df[idx]\n",
    "df.drop(columns = 'oof_preds', inplace = True)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(k['aff'].apply(lambda x: 1 if x >= (1-log (500)/log(50000)) else 0), k['oof_preds'])\n",
    "#df.drop(columns='oof_preds',axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.drop(columns = ['aff', 'true_index','n_label']).to_csv('stage2_input.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = feature_importance_df.groupby('feature').agg({'importance':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>allele_type</th>\n",
       "      <td>3.564324e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len_peptide_transform</th>\n",
       "      <td>2.315711e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len_LPFR</th>\n",
       "      <td>4.922416e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_P3_std</th>\n",
       "      <td>6.487726e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_P7</th>\n",
       "      <td>6.917599e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_P8</th>\n",
       "      <td>7.031290e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_P5_std</th>\n",
       "      <td>7.104426e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_P5</th>\n",
       "      <td>7.144126e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_P4_std</th>\n",
       "      <td>7.283346e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_P2_std</th>\n",
       "      <td>7.380846e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len_RPFR</th>\n",
       "      <td>7.459643e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_P6</th>\n",
       "      <td>7.496511e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_P2</th>\n",
       "      <td>7.759445e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_P9</th>\n",
       "      <td>7.764742e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_P3</th>\n",
       "      <td>8.073460e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_P1_std</th>\n",
       "      <td>8.093486e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_P9_std</th>\n",
       "      <td>8.221072e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_P4</th>\n",
       "      <td>8.504176e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_P8_std</th>\n",
       "      <td>8.582440e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_P1</th>\n",
       "      <td>8.605797e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPFR_P1_std</th>\n",
       "      <td>9.038991e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_P7_std</th>\n",
       "      <td>9.393219e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_P6_std</th>\n",
       "      <td>9.535586e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p8</th>\n",
       "      <td>9.811480e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p9</th>\n",
       "      <td>1.021961e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPFR_P2_std</th>\n",
       "      <td>1.029758e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_P7_mean</th>\n",
       "      <td>1.078536e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPFR_P1</th>\n",
       "      <td>1.108084e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_P8_mean</th>\n",
       "      <td>1.117633e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p2</th>\n",
       "      <td>1.119541e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p1</th>\n",
       "      <td>1.119606e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_P9_mean</th>\n",
       "      <td>1.147770e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPFR_P2_std</th>\n",
       "      <td>1.155938e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p7</th>\n",
       "      <td>1.172075e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p6</th>\n",
       "      <td>1.190928e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_P6_mean</th>\n",
       "      <td>1.206605e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPFR_P2</th>\n",
       "      <td>1.210085e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p5</th>\n",
       "      <td>1.249317e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPFR_P1_std</th>\n",
       "      <td>1.255573e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPFR_P3</th>\n",
       "      <td>1.271279e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPFR_P1</th>\n",
       "      <td>1.280440e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPFR_P3_std</th>\n",
       "      <td>1.354281e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p3</th>\n",
       "      <td>1.376768e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPFR_P2</th>\n",
       "      <td>1.389268e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_c_tfidf</th>\n",
       "      <td>1.393344e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p4</th>\n",
       "      <td>1.410822e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPFR_P3_std</th>\n",
       "      <td>1.493653e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPFR_P3</th>\n",
       "      <td>1.501648e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_P5_mean</th>\n",
       "      <td>1.537837e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_h_tfidf</th>\n",
       "      <td>1.807938e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_P2_mean</th>\n",
       "      <td>2.017041e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_P4_mean</th>\n",
       "      <td>2.021115e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_w_tfidf</th>\n",
       "      <td>2.059474e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_m_tfidf</th>\n",
       "      <td>2.098941e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_P1_mean</th>\n",
       "      <td>2.143310e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_P3_mean</th>\n",
       "      <td>2.282007e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_q_tfidf</th>\n",
       "      <td>2.386528e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_y_tfidf</th>\n",
       "      <td>2.514543e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <td>2.665380e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allele_type_std</th>\n",
       "      <td>2.834665e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPFR_P1_mean</th>\n",
       "      <td>3.032358e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPFR_P2_mean</th>\n",
       "      <td>3.138706e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_s_tfidf</th>\n",
       "      <td>3.164958e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPFR_P1_mean</th>\n",
       "      <td>3.210617e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_v_tfidf</th>\n",
       "      <td>3.235131e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_n_tfidf</th>\n",
       "      <td>3.434504e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_p_tfidf</th>\n",
       "      <td>3.489502e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPFR_P3_mean</th>\n",
       "      <td>3.556107e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPFR_P2_mean</th>\n",
       "      <td>3.595138e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_t_tfidf</th>\n",
       "      <td>3.604256e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blosum_sum</th>\n",
       "      <td>3.798460e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_i_tfidf</th>\n",
       "      <td>4.049480e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allele_type_mean</th>\n",
       "      <td>4.130093e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPFR_P3_mean</th>\n",
       "      <td>4.268314e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_r_tfidf</th>\n",
       "      <td>4.353936e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nunique</th>\n",
       "      <td>4.740995e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_f_tfidf</th>\n",
       "      <td>5.257628e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_std</th>\n",
       "      <td>5.315174e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_k_tfidf</th>\n",
       "      <td>5.496016e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_g_tfidf</th>\n",
       "      <td>5.845805e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_e_tfidf</th>\n",
       "      <td>5.863837e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_rate</th>\n",
       "      <td>7.504476e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_d_tfidf</th>\n",
       "      <td>9.561622e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length</th>\n",
       "      <td>1.059019e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_l_tfidf</th>\n",
       "      <td>1.061657e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>core_a_tfidf</th>\n",
       "      <td>1.064268e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_std</th>\n",
       "      <td>1.970487e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla</th>\n",
       "      <td>2.292649e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_mean</th>\n",
       "      <td>4.772265e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hla_mean</th>\n",
       "      <td>5.454255e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         importance\n",
       "feature                            \n",
       "allele_type            3.564324e+03\n",
       "len_peptide_transform  2.315711e+04\n",
       "len_LPFR               4.922416e+04\n",
       "core_P3_std            6.487726e+04\n",
       "core_P7                6.917599e+04\n",
       "core_P8                7.031290e+04\n",
       "core_P5_std            7.104426e+04\n",
       "core_P5                7.144126e+04\n",
       "core_P4_std            7.283346e+04\n",
       "core_P2_std            7.380846e+04\n",
       "len_RPFR               7.459643e+04\n",
       "core_P6                7.496511e+04\n",
       "core_P2                7.759445e+04\n",
       "core_P9                7.764742e+04\n",
       "core_P3                8.073460e+04\n",
       "core_P1_std            8.093486e+04\n",
       "core_P9_std            8.221072e+04\n",
       "core_P4                8.504176e+04\n",
       "core_P8_std            8.582440e+04\n",
       "core_P1                8.605797e+04\n",
       "RPFR_P1_std            9.038991e+04\n",
       "core_P7_std            9.393219e+04\n",
       "core_P6_std            9.535586e+04\n",
       "p8                     9.811480e+04\n",
       "p9                     1.021961e+05\n",
       "LPFR_P2_std            1.029758e+05\n",
       "core_P7_mean           1.078536e+05\n",
       "LPFR_P1                1.108084e+05\n",
       "core_P8_mean           1.117633e+05\n",
       "p2                     1.119541e+05\n",
       "p1                     1.119606e+05\n",
       "core_P9_mean           1.147770e+05\n",
       "RPFR_P2_std            1.155938e+05\n",
       "p7                     1.172075e+05\n",
       "p6                     1.190928e+05\n",
       "core_P6_mean           1.206605e+05\n",
       "LPFR_P2                1.210085e+05\n",
       "p5                     1.249317e+05\n",
       "LPFR_P1_std            1.255573e+05\n",
       "LPFR_P3                1.271279e+05\n",
       "RPFR_P1                1.280440e+05\n",
       "LPFR_P3_std            1.354281e+05\n",
       "p3                     1.376768e+05\n",
       "RPFR_P2                1.389268e+05\n",
       "core_c_tfidf           1.393344e+05\n",
       "p4                     1.410822e+05\n",
       "RPFR_P3_std            1.493653e+05\n",
       "RPFR_P3                1.501648e+05\n",
       "core_P5_mean           1.537837e+05\n",
       "core_h_tfidf           1.807938e+05\n",
       "core_P2_mean           2.017041e+05\n",
       "core_P4_mean           2.021115e+05\n",
       "core_w_tfidf           2.059474e+05\n",
       "core_m_tfidf           2.098941e+05\n",
       "core_P1_mean           2.143310e+05\n",
       "core_P3_mean           2.282007e+05\n",
       "core_q_tfidf           2.386528e+05\n",
       "core_y_tfidf           2.514543e+05\n",
       "cluster                2.665380e+05\n",
       "allele_type_std        2.834665e+05\n",
       "LPFR_P1_mean           3.032358e+05\n",
       "RPFR_P2_mean           3.138706e+05\n",
       "core_s_tfidf           3.164958e+05\n",
       "RPFR_P1_mean           3.210617e+05\n",
       "core_v_tfidf           3.235131e+05\n",
       "core_n_tfidf           3.434504e+05\n",
       "core_p_tfidf           3.489502e+05\n",
       "RPFR_P3_mean           3.556107e+05\n",
       "LPFR_P2_mean           3.595138e+05\n",
       "core_t_tfidf           3.604256e+05\n",
       "blosum_sum             3.798460e+05\n",
       "core_i_tfidf           4.049480e+05\n",
       "allele_type_mean       4.130093e+05\n",
       "LPFR_P3_mean           4.268314e+05\n",
       "core_r_tfidf           4.353936e+05\n",
       "peptide_nunique        4.740995e+05\n",
       "core_f_tfidf           5.257628e+05\n",
       "cluster_std            5.315174e+05\n",
       "core_k_tfidf           5.496016e+05\n",
       "core_g_tfidf           5.845805e+05\n",
       "core_e_tfidf           5.863837e+05\n",
       "unique_rate            7.504476e+05\n",
       "core_d_tfidf           9.561622e+05\n",
       "length                 1.059019e+06\n",
       "core_l_tfidf           1.061657e+06\n",
       "core_a_tfidf           1.064268e+06\n",
       "hla_std                1.970487e+06\n",
       "hla                    2.292649e+06\n",
       "cluster_mean           4.772265e+06\n",
       "hla_mean               5.454255e+06"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 100\n",
    "a.sort_values(by = 'importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_index</th>\n",
       "      <th>peptide</th>\n",
       "      <th>hla</th>\n",
       "      <th>aff</th>\n",
       "      <th>allele_type</th>\n",
       "      <th>length</th>\n",
       "      <th>n_label</th>\n",
       "      <th>core</th>\n",
       "      <th>LPFR</th>\n",
       "      <th>RPFR</th>\n",
       "      <th>len_LPFR</th>\n",
       "      <th>len_RPFR</th>\n",
       "      <th>len_peptide_transform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AAAAAAAAAAA</td>\n",
       "      <td>37</td>\n",
       "      <td>0.324088</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>AAAAAAAAA</td>\n",
       "      <td></td>\n",
       "      <td>AA</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.880797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AAAAAAAAAAA</td>\n",
       "      <td>37</td>\n",
       "      <td>0.324088</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>AAAAAAAAA</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.880797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>AAAAAAAAAAA</td>\n",
       "      <td>37</td>\n",
       "      <td>0.324088</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>AAAAAAAAA</td>\n",
       "      <td>AA</td>\n",
       "      <td></td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>AAAAAGTTVYGAFAA</td>\n",
       "      <td>46</td>\n",
       "      <td>0.129502</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>AAAAAGTTV</td>\n",
       "      <td></td>\n",
       "      <td>YGA</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>AAAAAGTTVYGAFAA</td>\n",
       "      <td>46</td>\n",
       "      <td>0.129502</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>AAAAGTTVY</td>\n",
       "      <td>A</td>\n",
       "      <td>GAF</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true_index          peptide  hla       aff  allele_type  length  n_label  \\\n",
       "0           1      AAAAAAAAAAA   37  0.324088            1      11        0   \n",
       "1           1      AAAAAAAAAAA   37  0.324088            1      11        1   \n",
       "2           1      AAAAAAAAAAA   37  0.324088            1      11        2   \n",
       "3           2  AAAAAGTTVYGAFAA   46  0.129502            2      15        0   \n",
       "4           2  AAAAAGTTVYGAFAA   46  0.129502            2      15        1   \n",
       "\n",
       "        core LPFR RPFR  len_LPFR  len_RPFR  len_peptide_transform  \n",
       "0  AAAAAAAAA        AA  0.000000  0.666667               0.880797  \n",
       "1  AAAAAAAAA    A    A  0.333333  0.333333               0.880797  \n",
       "2  AAAAAAAAA   AA       0.666667  0.000000               0.880797  \n",
       "3  AAAAAGTTV       YGA  0.000000  1.000000               0.500000  \n",
       "4  AAAAGTTVY    A  GAF  0.333333  1.000000               0.500000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.to_csv('stage2_input3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_index</th>\n",
       "      <th>peptide</th>\n",
       "      <th>hla</th>\n",
       "      <th>aff</th>\n",
       "      <th>allele_type</th>\n",
       "      <th>length</th>\n",
       "      <th>n_label</th>\n",
       "      <th>core</th>\n",
       "      <th>LPFR</th>\n",
       "      <th>RPFR</th>\n",
       "      <th>len_LPFR</th>\n",
       "      <th>len_RPFR</th>\n",
       "      <th>len_peptide_transform</th>\n",
       "      <th>core_P1</th>\n",
       "      <th>core_P2</th>\n",
       "      <th>core_P3</th>\n",
       "      <th>core_P4</th>\n",
       "      <th>core_P5</th>\n",
       "      <th>core_P6</th>\n",
       "      <th>core_P7</th>\n",
       "      <th>core_P8</th>\n",
       "      <th>core_P9</th>\n",
       "      <th>LPFR_P1</th>\n",
       "      <th>LPFR_P2</th>\n",
       "      <th>LPFR_P3</th>\n",
       "      <th>RPFR_P1</th>\n",
       "      <th>RPFR_P2</th>\n",
       "      <th>RPFR_P3</th>\n",
       "      <th>core_a_tfidf</th>\n",
       "      <th>core_c_tfidf</th>\n",
       "      <th>core_d_tfidf</th>\n",
       "      <th>core_e_tfidf</th>\n",
       "      <th>core_f_tfidf</th>\n",
       "      <th>core_g_tfidf</th>\n",
       "      <th>core_h_tfidf</th>\n",
       "      <th>core_i_tfidf</th>\n",
       "      <th>core_k_tfidf</th>\n",
       "      <th>core_l_tfidf</th>\n",
       "      <th>core_m_tfidf</th>\n",
       "      <th>core_n_tfidf</th>\n",
       "      <th>core_p_tfidf</th>\n",
       "      <th>core_q_tfidf</th>\n",
       "      <th>core_r_tfidf</th>\n",
       "      <th>core_s_tfidf</th>\n",
       "      <th>core_t_tfidf</th>\n",
       "      <th>core_v_tfidf</th>\n",
       "      <th>core_w_tfidf</th>\n",
       "      <th>core_y_tfidf</th>\n",
       "      <th>cluster</th>\n",
       "      <th>hla_mean</th>\n",
       "      <th>hla_std</th>\n",
       "      <th>allele_type_mean</th>\n",
       "      <th>allele_type_std</th>\n",
       "      <th>core_P1_mean</th>\n",
       "      <th>core_P1_std</th>\n",
       "      <th>core_P2_mean</th>\n",
       "      <th>core_P2_std</th>\n",
       "      <th>core_P3_mean</th>\n",
       "      <th>core_P3_std</th>\n",
       "      <th>core_P4_mean</th>\n",
       "      <th>core_P4_std</th>\n",
       "      <th>core_P5_mean</th>\n",
       "      <th>core_P5_std</th>\n",
       "      <th>core_P6_mean</th>\n",
       "      <th>core_P6_std</th>\n",
       "      <th>core_P7_mean</th>\n",
       "      <th>core_P7_std</th>\n",
       "      <th>core_P8_mean</th>\n",
       "      <th>core_P8_std</th>\n",
       "      <th>core_P9_mean</th>\n",
       "      <th>core_P9_std</th>\n",
       "      <th>LPFR_P1_mean</th>\n",
       "      <th>LPFR_P1_std</th>\n",
       "      <th>LPFR_P2_mean</th>\n",
       "      <th>LPFR_P2_std</th>\n",
       "      <th>LPFR_P3_mean</th>\n",
       "      <th>LPFR_P3_std</th>\n",
       "      <th>RPFR_P1_mean</th>\n",
       "      <th>RPFR_P1_std</th>\n",
       "      <th>RPFR_P2_mean</th>\n",
       "      <th>RPFR_P2_std</th>\n",
       "      <th>RPFR_P3_mean</th>\n",
       "      <th>RPFR_P3_std</th>\n",
       "      <th>cluster_mean</th>\n",
       "      <th>cluster_std</th>\n",
       "      <th>peptide_nunique</th>\n",
       "      <th>unique_rate</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>p5</th>\n",
       "      <th>p6</th>\n",
       "      <th>p7</th>\n",
       "      <th>p8</th>\n",
       "      <th>p9</th>\n",
       "      <th>blosum_sum</th>\n",
       "      <th>oof_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>553288</th>\n",
       "      <td>75918</td>\n",
       "      <td>LQLQPFPQPQLPYPQPQLPYPQPQLPYPQPQPF</td>\n",
       "      <td>73</td>\n",
       "      <td>0.273745</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>LPYPQPQLP</td>\n",
       "      <td>QPQ</td>\n",
       "      <td>YPQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.305176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.442139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225952</td>\n",
       "      <td>58</td>\n",
       "      <td>0.314281</td>\n",
       "      <td>0.204903</td>\n",
       "      <td>0.325156</td>\n",
       "      <td>0.230245</td>\n",
       "      <td>0.410244</td>\n",
       "      <td>0.257913</td>\n",
       "      <td>0.313028</td>\n",
       "      <td>0.250265</td>\n",
       "      <td>0.409004</td>\n",
       "      <td>0.264242</td>\n",
       "      <td>0.321826</td>\n",
       "      <td>0.25468</td>\n",
       "      <td>0.37623</td>\n",
       "      <td>0.264482</td>\n",
       "      <td>0.3514</td>\n",
       "      <td>0.26912</td>\n",
       "      <td>0.377549</td>\n",
       "      <td>0.261341</td>\n",
       "      <td>0.413677</td>\n",
       "      <td>0.262606</td>\n",
       "      <td>0.373957</td>\n",
       "      <td>0.272327</td>\n",
       "      <td>0.390232</td>\n",
       "      <td>0.249063</td>\n",
       "      <td>0.323595</td>\n",
       "      <td>0.249211</td>\n",
       "      <td>0.374778</td>\n",
       "      <td>0.250029</td>\n",
       "      <td>0.361677</td>\n",
       "      <td>0.252535</td>\n",
       "      <td>0.390704</td>\n",
       "      <td>0.274232</td>\n",
       "      <td>0.340601</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.209152</td>\n",
       "      <td>0.231298</td>\n",
       "      <td>5</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>-9</td>\n",
       "      <td>17</td>\n",
       "      <td>-9</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>17</td>\n",
       "      <td>43</td>\n",
       "      <td>0.000112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553295</th>\n",
       "      <td>75918</td>\n",
       "      <td>LQLQPFPQPQLPYPQPQLPYPQPQLPYPQPQPF</td>\n",
       "      <td>73</td>\n",
       "      <td>0.273745</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "      <td>LPYPQPQLP</td>\n",
       "      <td>QPQ</td>\n",
       "      <td>YPQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.305176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.442139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225952</td>\n",
       "      <td>58</td>\n",
       "      <td>0.314281</td>\n",
       "      <td>0.204903</td>\n",
       "      <td>0.325156</td>\n",
       "      <td>0.230245</td>\n",
       "      <td>0.410244</td>\n",
       "      <td>0.257913</td>\n",
       "      <td>0.313028</td>\n",
       "      <td>0.250265</td>\n",
       "      <td>0.409004</td>\n",
       "      <td>0.264242</td>\n",
       "      <td>0.321826</td>\n",
       "      <td>0.25468</td>\n",
       "      <td>0.37623</td>\n",
       "      <td>0.264482</td>\n",
       "      <td>0.3514</td>\n",
       "      <td>0.26912</td>\n",
       "      <td>0.377549</td>\n",
       "      <td>0.261341</td>\n",
       "      <td>0.413677</td>\n",
       "      <td>0.262606</td>\n",
       "      <td>0.373957</td>\n",
       "      <td>0.272327</td>\n",
       "      <td>0.390232</td>\n",
       "      <td>0.249063</td>\n",
       "      <td>0.323595</td>\n",
       "      <td>0.249211</td>\n",
       "      <td>0.374778</td>\n",
       "      <td>0.250029</td>\n",
       "      <td>0.361677</td>\n",
       "      <td>0.252535</td>\n",
       "      <td>0.390704</td>\n",
       "      <td>0.274232</td>\n",
       "      <td>0.340601</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.209152</td>\n",
       "      <td>0.231298</td>\n",
       "      <td>5</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>-9</td>\n",
       "      <td>17</td>\n",
       "      <td>-9</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>17</td>\n",
       "      <td>43</td>\n",
       "      <td>0.000112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        true_index                            peptide  hla       aff  \\\n",
       "553288       75918  LQLQPFPQPQLPYPQPQLPYPQPQLPYPQPQPF   73  0.273745   \n",
       "553295       75918  LQLQPFPQPQLPYPQPQLPYPQPQLPYPQPQPF   73  0.273745   \n",
       "\n",
       "        allele_type  length  n_label       core LPFR RPFR  len_LPFR  len_RPFR  \\\n",
       "553288            3      33       10  LPYPQPQLP  QPQ  YPQ       1.0       1.0   \n",
       "553295            3      33       17  LPYPQPQLP  QPQ  YPQ       1.0       1.0   \n",
       "\n",
       "        len_peptide_transform  core_P1  core_P2  core_P3  core_P4  core_P5  \\\n",
       "553288               0.000123        9       12       19       12       13   \n",
       "553295               0.000123        9       12       19       12       13   \n",
       "\n",
       "        core_P6  core_P7  core_P8  core_P9  LPFR_P1  LPFR_P2  LPFR_P3  \\\n",
       "553288       12       13        9       12       14       13       14   \n",
       "553295       12       13        9       12       14       13       14   \n",
       "\n",
       "        RPFR_P1  RPFR_P2  RPFR_P3  core_a_tfidf  core_c_tfidf  core_d_tfidf  \\\n",
       "553288       20       13       14           0.0           0.0           0.0   \n",
       "553295       20       13       14           0.0           0.0           0.0   \n",
       "\n",
       "        core_e_tfidf  core_f_tfidf  core_g_tfidf  core_h_tfidf  core_i_tfidf  \\\n",
       "553288           0.0           0.0           0.0           0.0           0.0   \n",
       "553295           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "        core_k_tfidf  core_l_tfidf  core_m_tfidf  core_n_tfidf  core_p_tfidf  \\\n",
       "553288           0.0      0.305176           0.0           0.0        0.8125   \n",
       "553295           0.0      0.305176           0.0           0.0        0.8125   \n",
       "\n",
       "        core_q_tfidf  core_r_tfidf  core_s_tfidf  core_t_tfidf  core_v_tfidf  \\\n",
       "553288      0.442139           0.0           0.0           0.0           0.0   \n",
       "553295      0.442139           0.0           0.0           0.0           0.0   \n",
       "\n",
       "        core_w_tfidf  core_y_tfidf  cluster  hla_mean   hla_std  \\\n",
       "553288           0.0      0.225952       58  0.314281  0.204903   \n",
       "553295           0.0      0.225952       58  0.314281  0.204903   \n",
       "\n",
       "        allele_type_mean  allele_type_std  core_P1_mean  core_P1_std  \\\n",
       "553288          0.325156         0.230245      0.410244     0.257913   \n",
       "553295          0.325156         0.230245      0.410244     0.257913   \n",
       "\n",
       "        core_P2_mean  core_P2_std  core_P3_mean  core_P3_std  core_P4_mean  \\\n",
       "553288      0.313028     0.250265      0.409004     0.264242      0.321826   \n",
       "553295      0.313028     0.250265      0.409004     0.264242      0.321826   \n",
       "\n",
       "        core_P4_std  core_P5_mean  core_P5_std  core_P6_mean  core_P6_std  \\\n",
       "553288      0.25468       0.37623     0.264482        0.3514      0.26912   \n",
       "553295      0.25468       0.37623     0.264482        0.3514      0.26912   \n",
       "\n",
       "        core_P7_mean  core_P7_std  core_P8_mean  core_P8_std  core_P9_mean  \\\n",
       "553288      0.377549     0.261341      0.413677     0.262606      0.373957   \n",
       "553295      0.377549     0.261341      0.413677     0.262606      0.373957   \n",
       "\n",
       "        core_P9_std  LPFR_P1_mean  LPFR_P1_std  LPFR_P2_mean  LPFR_P2_std  \\\n",
       "553288     0.272327      0.390232     0.249063      0.323595     0.249211   \n",
       "553295     0.272327      0.390232     0.249063      0.323595     0.249211   \n",
       "\n",
       "        LPFR_P3_mean  LPFR_P3_std  RPFR_P1_mean  RPFR_P1_std  RPFR_P2_mean  \\\n",
       "553288      0.374778     0.250029      0.361677     0.252535      0.390704   \n",
       "553295      0.374778     0.250029      0.361677     0.252535      0.390704   \n",
       "\n",
       "        RPFR_P2_std  RPFR_P3_mean  RPFR_P3_std  cluster_mean  cluster_std  \\\n",
       "553288     0.274232      0.340601     0.247934      0.209152     0.231298   \n",
       "553295     0.274232      0.340601     0.247934      0.209152     0.231298   \n",
       "\n",
       "        peptide_nunique  unique_rate  p1  p2  p3  p4  p5  p6  p7  p8  p9  \\\n",
       "553288                5     0.151515  -9  17  -9  17   1  17   1  -9  17   \n",
       "553295                5     0.151515  -9  17  -9  17   1  17   1  -9  17   \n",
       "\n",
       "        blosum_sum  oof_preds  \n",
       "553288          43   0.000112  \n",
       "553295          43   0.000112  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k[k['true_index'] == 75918]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "version3_Preprocess_len9.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
