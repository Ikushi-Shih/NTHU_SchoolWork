{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing may take about 5 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:156: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:157: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:158: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      " 13%|█▎        | 8/60 [00:36<03:57,  4.57s/it]/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:128: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/usr/local/lib/python3.6/site-packages/scipy/optimize/optimize.py:1929: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  p = (x - v) * tmp2 - (x - w) * tmp1\n",
      "/usr/local/lib/python3.6/site-packages/scipy/optimize/optimize.py:1930: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  tmp2 = 2.0 * (tmp2 - tmp1)\n",
      "/usr/local/lib/python3.6/site-packages/scipy/optimize/optimize.py:1928: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  tmp2 = (x - v) * (fx - fw)\n",
      "/usr/local/lib/python3.6/site-packages/scipy/optimize/optimize.py:1927: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  tmp1 = (x - w) * (fx - fv)\n",
      "/usr/local/lib/python3.6/site-packages/scipy/optimize/optimize.py:2574: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if (fx2 - fval) > delta:\n",
      " 50%|█████     | 30/60 [02:30<02:30,  5.01s/it]/usr/local/lib/python3.6/site-packages/scipy/optimize/optimize.py:2599: RuntimeWarning: overflow encountered in double_scalars\n",
      "  t *= temp*temp\n",
      "100%|██████████| 60/60 [05:20<00:00,  5.34s/it]\n",
      "100%|██████████| 2675/2675 [00:00<00:00, 3366.73it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.optimize as optimize\n",
    "#data reading and cleaning\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "print('Preprocessing may take about 5 minutes')\n",
    "items = pd.read_csv('Data/items.csv')\n",
    "samples = pd.read_csv('Data/samples.csv')\n",
    "test = pd.read_csv('Data/test.csv')\n",
    "train = pd.read_csv('Data/train.csv')\n",
    "users = pd.read_csv('Data/users.csv')\n",
    "\n",
    "\n",
    "train_cols ={\n",
    "    'User ID':'usr_id',\n",
    "    'Item1 ID':'item1_id',\n",
    "    'Item2 ID':'item2_id',\n",
    "    'Preference':'preference'\n",
    "}\n",
    "train = train.rename(columns=train_cols)\n",
    "\n",
    "test_cols ={\n",
    "    'User ID':'usr_id',\n",
    "    'Item1 ID':'item1_id',\n",
    "    'Item2 ID':'item2_id',\n",
    "}\n",
    "test = test.rename(columns=test_cols)\n",
    "\n",
    "users_cols ={\n",
    "    'User ID':'usr_id',\n",
    "    ' Education':'education',\n",
    "    ' Age':'age',\n",
    "    ' Gender':'gender',\n",
    "    ' Region':'region'\n",
    "}\n",
    "users = users.rename(columns=users_cols)\n",
    "\n",
    "# data merging\n",
    "\n",
    "item1_cols ={\n",
    "    'Item ID':'item1_id',\n",
    "    ' BodyType':'body_type_1',\n",
    "    ' Transmission':'transmission_1',\n",
    "    ' Engin Capacity':'engin_capacity_1',\n",
    "    ' Fuel Consumed':'fuel_consumed_1'\n",
    "}\n",
    "\n",
    "item2_cols ={\n",
    "    'Item ID':'item2_id',\n",
    "    ' BodyType':'body_type_2',\n",
    "    ' Transmission':'transmission_2',\n",
    "    ' Engin Capacity':'engin_capacity_2',\n",
    "    ' Fuel Consumed':'fuel_consumed_2'\n",
    "}\n",
    "\n",
    "def find_winner():\n",
    "    k = pd.read_csv('Data/train.csv')\n",
    "    train_cols ={\n",
    "        'User ID':'usr_id',\n",
    "        'Item1 ID':'item1_id',\n",
    "        'Item2 ID':'item2_id',\n",
    "        'Preference':'preference'\n",
    "    }\n",
    "    k = k.rename(columns=train_cols)\n",
    "\n",
    "    win=list()\n",
    "    for index in k.index:\n",
    "        if k.preference[index] ==0:\n",
    "            win.append(k.item1_id[index])\n",
    "        else:\n",
    "            win.append(k.item2_id[index])\n",
    "    k['win'] = win\n",
    "    \n",
    "    return k\n",
    "\n",
    "def number_count(k):\n",
    "    k = k.drop(columns=['preference','win'])\n",
    "\n",
    "    p1 = k.pivot_table(index = ['usr_id'],columns=['item1_id'], aggfunc='count').fillna(0)\n",
    "    p2= k.pivot_table(index = ['usr_id'],columns=['item2_id'], aggfunc='count').fillna(0)\n",
    "\n",
    "    p1.columns = p1.columns.to_series().str.join('_')\n",
    "    p2.columns = p2.columns.to_series().str.join('_')\n",
    "\n",
    "    p1.columns = ['1_count','2_count','3_count','4_count','5_count',\n",
    "                 '6_count','7_count','8_count','9_count','10_count']\n",
    "\n",
    "    p2.columns = ['1_count','2_count','3_count','4_count','5_count',\n",
    "                 '6_count','7_count','8_count','9_count','10_count']\n",
    "    del p1.index.name, p2.index.name\n",
    "    return p1+p2\n",
    "\n",
    "def winner_count(k):\n",
    "    k = k.drop(columns=['item1_id','item2_id'])\n",
    "\n",
    "    result = k.pivot_table(index = ['usr_id'],columns=['win'], aggfunc='count')\n",
    "\n",
    "    result.columns.to_series().str.join('_')\n",
    "    del result.index.name\n",
    "\n",
    "    #result.columns = result.columns.get_level_values(0)\n",
    "    result.columns = ['1_count','2_count','3_count','4_count','5_count',\n",
    "                 '6_count','7_count','8_count','9_count','10_count']\n",
    "    return result\n",
    "\n",
    "def occur_rate(k):\n",
    "    k = (k/9).fillna(0)\n",
    "    k['usr_id'] = k.index\n",
    "    \n",
    "    return k\n",
    "\n",
    "def win_rate(w_count,n_count):\n",
    "    k = (w_count/n_count).fillna(0)\n",
    "    k.columns = ['1_win','2_win','3_win','4_win','5_win',\n",
    "                '6_win','7_win','8_win','9_win','10_win']\n",
    "    k['usr_id'] = k.index\n",
    "    \n",
    "    return k\n",
    "    \n",
    "def max_f(params):\n",
    "    r1,r2,r3,r4,r5,r6,r7,r8,r9,r10 = params\n",
    "    R = [r1,r2,r3,r4,r5,r6,r7,r8,r9,r10]\n",
    "    index:int\n",
    "    result = 1\n",
    "    for index in data.index:\n",
    "        result *= R[data.win[index]-1] / (R[data.item1_id[index]-1] + R[data.item2_id[index]-1])\n",
    "        \n",
    "    return -result\n",
    "\n",
    "\n",
    "#calculate occur times and win rate\n",
    "\n",
    "winner_list = find_winner()\n",
    "n_count = number_count(winner_list)\n",
    "w_count = winner_count(winner_list)\n",
    "occur = occur_rate(n_count)\n",
    "win = win_rate(w_count,n_count)\n",
    "\n",
    "#concat train and test\n",
    "df = pd.concat([train,test])\n",
    "item_1 = items.copy().rename(columns = item1_cols)\n",
    "item_2 = items.copy().rename(columns = item2_cols)\n",
    "df = pd.merge(df,users, on =['usr_id'])\n",
    "df = pd.merge(df,item_1, on =['item1_id'])\n",
    "df = pd.merge(df,item_2, on =['item2_id'])\n",
    "df.shape\n",
    "\n",
    "del item_1,item_2\n",
    "gc.collect()\n",
    "#feature generation\n",
    "#df = pd.merge(df,occur,on = ['usr_id'])\n",
    "df = pd.merge(df,win,on = ['usr_id'])\n",
    "df['engin2_bigger'] = 0\n",
    "df.engin2_bigger[df.engin_capacity_1==df.engin_capacity_2] = 2\n",
    "df.engin2_bigger[df.engin_capacity_1>df.engin_capacity_2] = 0\n",
    "df.engin2_bigger[df.engin_capacity_1<df.engin_capacity_2] = 1\n",
    "\n",
    "del n_count,w_count,occur,win\n",
    "gc.collect()\n",
    "\n",
    "#calculate likelyhood\n",
    "\n",
    "r_cobyla_list = list()\n",
    "r_powell_list = list()\n",
    "initial_guess = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "for i in tqdm(range(60)):\n",
    "    data = winner_list[winner_list['usr_id']==i]\n",
    "    result_cobyla = optimize.minimize(max_f, initial_guess, method='COBYLA')\n",
    "    result_powell = optimize.minimize(max_f, initial_guess, method='Powell')\n",
    "    r_cobyla_list.append(result_cobyla.x - result_cobyla.x.min() + 1)\n",
    "    r_powell_list.append(result_powell.x - result_powell.x.min()+1)\n",
    "    \n",
    "\n",
    "powell = list()\n",
    "cobylab = list()\n",
    "for index in tqdm(df.index):\n",
    "    R_powell = r_powell_list[df.usr_id[index]-1]\n",
    "    R_cobylab = r_cobyla_list[df.usr_id[index]-1]\n",
    "    prob_p = R_powell[df.item2_id[index]-1] / (R_powell[df.item1_id[index]-1] + R_powell[df.item2_id[index]-1])\n",
    "    prob_c = R_powell[df.item2_id[index]-1] / (R_powell[df.item1_id[index]-1] + R_powell[df.item2_id[index]-1])\n",
    "    \n",
    "    powell.append(prob_p)\n",
    "    cobylab.append(prob_c)\n",
    "    \n",
    "\n",
    "df['powell'] = powell\n",
    "#df['cobylab'] = cobylab\n",
    "\n",
    "del powell#, cobylab\n",
    "gc.collect()\n",
    "#split train test\n",
    "test = df[df.preference.isna()]\n",
    "train = df[df.preference.isna()==0]\n",
    "\n",
    "label = train.preference\n",
    "\n",
    "train = train.drop(columns=['preference'])\n",
    "test = test.drop(columns=['preference'])\n",
    "\n",
    "#train = train.drop(columns=['preference','usr_id','item1_id','item2_id'])\n",
    "#test = test.drop(columns=['preference','usr_id','item1_id','item2_id'])\n",
    "#train_test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, valid_data, train_target, valid_target = train_test_split(train, label, test_size=0.33, random_state=9)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy:0.6274944567627494\n",
      "KNN Accuracy:0.7095343680709535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Accuracy:0.8713968957871396\n",
      "Naive Bayes Accuracy:0.623059866962306\n",
      "SVM Accuracy:0.8248337028824834\n",
      "Neural Network Accuracy:0.8159645232815964\n",
      "Random Forest Accuracy:0.8226164079822617\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "classifier = LogisticRegression(C= 5.671226331427315, penalty= 'l1')  # 使用类，参数全是默认的  \n",
    "classifier.fit(train_data, train_target)  # 训练数据来学习，不需要返回值  \n",
    "#print(accuracy_score(valid_target, classifier.predict(valid_data)))\n",
    "\n",
    "lv2_logit = classifier.predict_proba(valid_data)[:,1]\n",
    "lv2_logit_test = classifier.predict_proba(test)[:,1]\n",
    "score = accuracy_score(valid_target,classifier.predict(valid_data))\n",
    "print('Logistic Regression Accuracy:{}'.format(score))\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(leaf_size= 29, n_neighbors= 9, p= 1, weights= 'distance')\n",
    "neigh.fit(train_data,train_target) \n",
    "\n",
    "lv2_knn = neigh.predict_proba(valid_data)[:,1]\n",
    "lv2_knn_test = neigh.predict_proba(test)[:,1]\n",
    "score = accuracy_score(valid_target, neigh.predict(valid_data))\n",
    "print('KNN Accuracy:{}'.format(score))\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "#test = test.drop(columns=['User-Item1-Item2','Preference'])\n",
    "clf = lgb.LGBMClassifier(bagging_fraction= 0.6508296012331772, bagging_freq= 1, boost= 'gbdt',\n",
    "                         feature_fraction= 0.3474516582970086, learning_rate= 0.16475833466929507,\n",
    "                         metric= 'binary_logloss', min_data_in_leaf= 52, num_leaves= 40, num_threads= 2,\n",
    "                         objective= 'binary', tree_learner= 'data')\n",
    "\n",
    "clf.fit(train_data, train_target)\n",
    "\n",
    "lv2_lgb = clf.predict_proba(valid_data)[:,1]\n",
    "lv2_lgb_test = clf.predict_proba(test)[:,1]\n",
    "score = accuracy_score(valid_target, clf.predict(valid_data))\n",
    "print('LGBM Accuracy:{}'.format(score))\n",
    "prediction = clf.predict(test)\n",
    "\n",
    "k = test.copy()\n",
    "k[\"User-Item1-Item2\"] = test['usr_id'].map(str)+'-'+test['item1_id'].map(str)+'-'+test['item2_id'].map(str)\n",
    "k['Preference'] = prediction.astype(np.int8)\n",
    "\n",
    "submission = k[['User-Item1-Item2','Preference']]\n",
    "\n",
    "submission.to_csv('LGB.csv',index = False)\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "NB = gnb.fit(train_data, train_target)\n",
    "\n",
    "lv2_nb = NB.predict_proba(valid_data)[:,1]\n",
    "lv2_nb_test = NB.predict_proba(test)[:,1]\n",
    "score = accuracy_score(valid_target, NB.predict(valid_data))\n",
    "print('Naive Bayes Accuracy:{}'.format(score))\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(C= 4.460710230756742, gamma= 0.013244596886327797, kernel= 'poly',probability=True)\n",
    "svm = svc.fit(train_data, train_target)\n",
    "\n",
    "lv2_svm = svm.predict_proba(valid_data)[:,1]\n",
    "lv2_svm_test = svm.predict_proba(test)[:,1]\n",
    "score = accuracy_score(valid_target, svm.predict(valid_data))\n",
    "print('SVM Accuracy:{}'.format(score))\n",
    "\n",
    "'''# Create your first MLP in Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# create model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=27, activation='relu'))\n",
    "model.add(Dense(36, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "#model.add(Dropout(p=0.01))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(train_data, train_target, epochs=10, batch_size=10)\n",
    "# evaluate the model\n",
    "scores = model.evaluate(valid_data, valid_target)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "lv2_keras = model.predict(valid_data)\n",
    "lv2_keras_test = model.predict(test)'''\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(activation= 'tanh', alpha= 1.6005926425406648e-08, hidden_layer_sizes= 83, solver= 'adam',\n",
    "                   random_state=42)\n",
    "mlp.fit(train_data, train_target)\n",
    "\n",
    "lv2_nn = mlp.predict_proba(valid_data)[:,1]\n",
    "lv2_nn_test = mlp.predict_proba(test)[:,1]\n",
    "score = accuracy_score(valid_target, mlp.predict(valid_data))\n",
    "print('Neural Network Accuracy:{}'.format(score))\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(bootstrap= 0, criterion= 'entropy', max_depth=24,\n",
    "                                    max_features= 0.3090928393734417, min_samples_leaf= 2,\n",
    "                                    n_estimators= 30, random_state= 40)\n",
    "classifier.fit(train_data, train_target)  \n",
    "\n",
    "lv2_RF = classifier.predict_proba(valid_data)[:,1]\n",
    "lv2_RF_test = classifier.predict_proba(test)[:,1]\n",
    "score = accuracy_score(valid_target, classifier.predict(valid_data))\n",
    "print('Random Forest Accuracy:{}'.format(score))\n",
    "\n",
    "lv2_df = np.column_stack((lv2_logit,lv2_knn,lv2_lgb,lv2_nb,lv2_nn,lv2_svm,lv2_RF))\n",
    "lv2_df = pd.DataFrame(lv2_df,columns=['logit', 'knn', 'lgb', 'nb','nn','svm','rf'])\n",
    "\n",
    "qtarget = valid_target.reset_index()['preference']\n",
    "#lv2_df['preference'] = qtarget\n",
    "lv2_train_data, lv2_valid_data, lv2_train_target, lv2_valid_target = train_test_split(lv2_df, qtarget, test_size=0.33, random_state=9)\n",
    "\n",
    "lv2_df_test = np.column_stack((lv2_logit_test,lv2_knn_test,lv2_lgb_test,lv2_nb_test,lv2_nn_test\n",
    "                               ,lv2_svm_test,lv2_RF_test))\n",
    "lv2_df_test = pd.DataFrame(lv2_df_test,columns=['logit', 'knn', 'lgb', 'nb','nn','svm','rf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(activation= 'tanh', alpha= 3.3527294273171613e-09, hidden_layer_sizes= 7, solver= 'sgd',\n",
    "                   random_state=42)\n",
    "mlp.fit(lv2_df, qtarget)\n",
    "\n",
    "prediction = mlp.predict(lv2_df_test)\n",
    "\n",
    "k = test.copy()\n",
    "k[\"User-Item1-Item2\"] = test['usr_id'].map(str)+'-'+test['item1_id'].map(str)+'-'+test['item2_id'].map(str)\n",
    "k['Preference'] = prediction.astype(np.int8)\n",
    "\n",
    "submission = k[['User-Item1-Item2','Preference']]\n",
    "\n",
    "submission.to_csv('Ensemble_mlp.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier(bagging_fraction= 0.6409803582029194, bagging_freq= 2, boost= 'dart',\n",
    "                         feature_fraction= 0.7076381520129653, learning_rate= 0.09672900472668634,\n",
    "                         min_data_in_leaf= 27, num_leaves= 74, tree_learner= 'serial')\n",
    "clf.fit(train,label)\n",
    "# 预测测试集\n",
    "prediction = clf.predict(test)\n",
    "\n",
    "k = test.copy()\n",
    "k[\"User-Item1-Item2\"] = test['usr_id'].map(str)+'-'+test['item1_id'].map(str)+'-'+test['item2_id'].map(str)\n",
    "k['Preference'] = prediction.astype(np.int8)\n",
    "\n",
    "submission = k[['User-Item1-Item2','Preference']]\n",
    "\n",
    "submission.to_csv('submission15_Lgb.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
